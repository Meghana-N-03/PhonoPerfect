{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9144580,"sourceType":"datasetVersion","datasetId":5523258},{"sourceId":9156393,"sourceType":"datasetVersion","datasetId":5531459}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-13T11:04:11.387968Z","iopub.execute_input":"2024-08-13T11:04:11.388536Z","iopub.status.idle":"2024-08-13T11:04:11.398644Z","shell.execute_reply.started":"2024-08-13T11:04:11.388497Z","shell.execute_reply":"2024-08-13T11:04:11.397669Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/cnn-model-correction/phoneme_correction_model.h5\n/kaggle/input/gru-dataset/capstone_dataset_hugging_face.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv1D, Dense, Embedding, Add, Multiply, Activation, Lambda, TimeDistributed\nimport tensorflow as tf\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-09-26T10:17:54.005298Z","iopub.execute_input":"2024-09-26T10:17:54.005975Z","iopub.status.idle":"2024-09-26T10:18:06.946156Z","shell.execute_reply.started":"2024-09-26T10:17:54.005945Z","shell.execute_reply":"2024-09-26T10:18:06.945379Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-09-26 10:17:56.751874: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-09-26 10:17:56.751987: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-09-26 10:17:56.887599: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the CSV file\nfile_path = '/kaggle/input/gru-dataset/capstone_dataset_hugging_face.csv'  # Replace with the path to your CSV file\ndf = pd.read_csv(file_path)\n\n# Combine all phoneme sequences to fit the tokenizer\nall_phonemes = list(df['ipa_phoneme']) + list(df['incorrect_ipa_phoneme'])\n\ntokenizer = Tokenizer(char_level=True)  # Use character-level tokenization\ntokenizer.fit_on_texts(all_phonemes)\n\n# Create tokenized sequences\ncorrect_sequences = tokenizer.texts_to_sequences(df['ipa_phoneme'])\nincorrect_sequences = tokenizer.texts_to_sequences(df['incorrect_ipa_phoneme'])\n\n# Pad sequences to the same length\nmax_sequence_length = max(max(len(seq) for seq in correct_sequences), max(len(seq) for seq in incorrect_sequences))\n\ncorrect_sequences = pad_sequences(correct_sequences, maxlen=max_sequence_length, padding='post')\nincorrect_sequences = pad_sequences(incorrect_sequences, maxlen=max_sequence_length, padding='post')","metadata":{"execution":{"iopub.status.busy":"2024-09-26T10:18:09.224045Z","iopub.execute_input":"2024-09-26T10:18:09.224675Z","iopub.status.idle":"2024-09-26T10:18:19.598045Z","shell.execute_reply.started":"2024-09-26T10:18:09.224644Z","shell.execute_reply":"2024-09-26T10:18:19.597013Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\n\n# Split the data into training and validation sets\ntrain_incorrect, val_incorrect, train_correct, val_correct = train_test_split(\n    incorrect_sequences, correct_sequences, test_size=0.2, random_state=42\n)\n\n# Prepare decoder input sequences for training (shifted incorrect sequences)\ntrain_decoder_input_sequences = np.zeros_like(train_incorrect)\ntrain_decoder_input_sequences[:, 1:] = train_incorrect[:, :-1]\n\nval_decoder_input_sequences = np.zeros_like(val_incorrect)\nval_decoder_input_sequences[:, 1:] = val_incorrect[:, :-1]\n\n# Prepare target sequences for training (correct sequences)\ntrain_decoder_target_sequences = train_correct\nval_decoder_target_sequences = val_correct\n\n# Define model parameters\nembedding_dim = 64\nnum_tokens = len(tokenizer.word_index) + 1  # +1 for padding token\n\n# Encoder\nencoder_inputs = Input(shape=(None,))\nencoder_embedding = Embedding(num_tokens, embedding_dim)(encoder_inputs)\nencoder_conv = Conv1D(filters=128, kernel_size=3, padding='same', activation='relu')\n(encoder_embedding)\n\n# Attention mechanism\nattention = Dense(1, activation='tanh')(encoder_conv)\nattention = Lambda(lambda x: tf.nn.softmax(x, axis=1))(attention) \n# Wrap softmax in a Lambda layer\nattention = Multiply()([encoder_conv, attention])\n\n# Decoder\ndecoder_inputs = Input(shape=(None,))\ndecoder_embedding = Embedding(num_tokens, embedding_dim)(decoder_inputs)\ndecoder_conv = Conv1D(filters=128, kernel_size=3, padding='same', activation='relu')\n(decoder_embedding)\n\n# Combine encoder output with attention and decoder output at each time step\ncombined = Add()([attention, decoder_conv])\n\n# TimeDistributed Dense layer to predict the next token for each timestep\ndecoder_dense = TimeDistributed(Dense(num_tokens, activation='softmax'))(combined)\n\n# Seq2Seq Model\nmodel = Model([encoder_inputs, decoder_inputs], decoder_dense)\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nhistory = model.fit(\n    [train_incorrect, train_decoder_input_sequences],\n    train_decoder_target_sequences,\n    epochs=50,\n    batch_size=64,\n    validation_data=([val_incorrect, val_decoder_input_sequences], val_decoder_target_sequences)\n)\n\n# Evaluate the model on the validation data\nval_loss, val_accuracy = model.evaluate([val_incorrect, val_decoder_input_sequences], val_decoder_target_sequences)\nprint(f\"Validation Accuracy: {val_accuracy:.4f}\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-12T07:35:08.684190Z","iopub.execute_input":"2024-08-12T07:35:08.684837Z","iopub.status.idle":"2024-08-12T07:47:16.160642Z","shell.execute_reply.started":"2024-08-12T07:35:08.684803Z","shell.execute_reply":"2024-08-12T07:47:16.159612Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m  42/3437\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.6352 - loss: 2.4883 ","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1723448137.515820     111 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - accuracy: 0.8563 - loss: 0.5684 - val_accuracy: 0.8826 - val_loss: 0.3434\nEpoch 2/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8843 - loss: 0.3354 - val_accuracy: 0.8858 - val_loss: 0.3189\nEpoch 3/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8867 - loss: 0.3138 - val_accuracy: 0.8881 - val_loss: 0.3056\nEpoch 4/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8886 - loss: 0.3022 - val_accuracy: 0.8884 - val_loss: 0.2993\nEpoch 5/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8887 - loss: 0.2977 - val_accuracy: 0.8898 - val_loss: 0.2957\nEpoch 6/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8900 - loss: 0.2932 - val_accuracy: 0.8902 - val_loss: 0.2921\nEpoch 7/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8904 - loss: 0.2900 - val_accuracy: 0.8906 - val_loss: 0.2899\nEpoch 8/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8908 - loss: 0.2879 - val_accuracy: 0.8903 - val_loss: 0.2893\nEpoch 9/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8912 - loss: 0.2858 - val_accuracy: 0.8906 - val_loss: 0.2878\nEpoch 10/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8915 - loss: 0.2846 - val_accuracy: 0.8911 - val_loss: 0.2852\nEpoch 11/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8917 - loss: 0.2831 - val_accuracy: 0.8903 - val_loss: 0.2859\nEpoch 12/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8918 - loss: 0.2819 - val_accuracy: 0.8915 - val_loss: 0.2842\nEpoch 13/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8923 - loss: 0.2811 - val_accuracy: 0.8915 - val_loss: 0.2827\nEpoch 14/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8923 - loss: 0.2800 - val_accuracy: 0.8925 - val_loss: 0.2821\nEpoch 15/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8924 - loss: 0.2793 - val_accuracy: 0.8919 - val_loss: 0.2811\nEpoch 16/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8930 - loss: 0.2780 - val_accuracy: 0.8923 - val_loss: 0.2808\nEpoch 17/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8927 - loss: 0.2779 - val_accuracy: 0.8923 - val_loss: 0.2800\nEpoch 18/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8931 - loss: 0.2769 - val_accuracy: 0.8925 - val_loss: 0.2795\nEpoch 19/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8930 - loss: 0.2768 - val_accuracy: 0.8928 - val_loss: 0.2798\nEpoch 20/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8928 - loss: 0.2770 - val_accuracy: 0.8928 - val_loss: 0.2799\nEpoch 21/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8930 - loss: 0.2762 - val_accuracy: 0.8922 - val_loss: 0.2791\nEpoch 22/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8930 - loss: 0.2756 - val_accuracy: 0.8927 - val_loss: 0.2782\nEpoch 23/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8933 - loss: 0.2750 - val_accuracy: 0.8926 - val_loss: 0.2783\nEpoch 24/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8930 - loss: 0.2753 - val_accuracy: 0.8926 - val_loss: 0.2776\nEpoch 25/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8936 - loss: 0.2744 - val_accuracy: 0.8924 - val_loss: 0.2778\nEpoch 26/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8937 - loss: 0.2741 - val_accuracy: 0.8928 - val_loss: 0.2774\nEpoch 27/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8938 - loss: 0.2737 - val_accuracy: 0.8928 - val_loss: 0.2771\nEpoch 28/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8938 - loss: 0.2736 - val_accuracy: 0.8925 - val_loss: 0.2772\nEpoch 29/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8937 - loss: 0.2733 - val_accuracy: 0.8932 - val_loss: 0.2767\nEpoch 30/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8938 - loss: 0.2733 - val_accuracy: 0.8934 - val_loss: 0.2758\nEpoch 31/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8937 - loss: 0.2734 - val_accuracy: 0.8926 - val_loss: 0.2759\nEpoch 32/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8938 - loss: 0.2728 - val_accuracy: 0.8929 - val_loss: 0.2763\nEpoch 33/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8937 - loss: 0.2731 - val_accuracy: 0.8928 - val_loss: 0.2761\nEpoch 34/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8939 - loss: 0.2725 - val_accuracy: 0.8928 - val_loss: 0.2764\nEpoch 35/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8937 - loss: 0.2726 - val_accuracy: 0.8926 - val_loss: 0.2762\nEpoch 36/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8938 - loss: 0.2726 - val_accuracy: 0.8926 - val_loss: 0.2759\nEpoch 37/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8943 - loss: 0.2712 - val_accuracy: 0.8932 - val_loss: 0.2760\nEpoch 38/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8940 - loss: 0.2720 - val_accuracy: 0.8929 - val_loss: 0.2756\nEpoch 39/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8942 - loss: 0.2715 - val_accuracy: 0.8921 - val_loss: 0.2762\nEpoch 40/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8938 - loss: 0.2718 - val_accuracy: 0.8929 - val_loss: 0.2755\nEpoch 41/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8946 - loss: 0.2706 - val_accuracy: 0.8928 - val_loss: 0.2753\nEpoch 42/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8944 - loss: 0.2710 - val_accuracy: 0.8934 - val_loss: 0.2745\nEpoch 43/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8943 - loss: 0.2711 - val_accuracy: 0.8933 - val_loss: 0.2754\nEpoch 44/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8940 - loss: 0.2713 - val_accuracy: 0.8932 - val_loss: 0.2745\nEpoch 45/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8941 - loss: 0.2709 - val_accuracy: 0.8934 - val_loss: 0.2751\nEpoch 46/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8939 - loss: 0.2713 - val_accuracy: 0.8925 - val_loss: 0.2753\nEpoch 47/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8947 - loss: 0.2703 - val_accuracy: 0.8926 - val_loss: 0.2752\nEpoch 48/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8940 - loss: 0.2713 - val_accuracy: 0.8930 - val_loss: 0.2747\nEpoch 49/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8946 - loss: 0.2700 - val_accuracy: 0.8929 - val_loss: 0.2744\nEpoch 50/50\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8944 - loss: 0.2702 - val_accuracy: 0.8933 - val_loss: 0.2748\n\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8927 - loss: 0.2758\nValidation Accuracy: 0.8933\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Save the entire model\nmodel.save('phoneme_correction_model.h5')\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-12T07:50:43.772299Z","iopub.execute_input":"2024-08-12T07:50:43.772937Z","iopub.status.idle":"2024-08-12T07:50:43.808246Z","shell.execute_reply.started":"2024-08-12T07:50:43.772906Z","shell.execute_reply":"2024-08-12T07:50:43.807356Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Rebuild the model architecture\nembedding_dim = 64\nnum_tokens = len(tokenizer.word_index) + 1\n\n# Encoder\nencoder_inputs = Input(shape=(None,))\nencoder_embedding = Embedding(num_tokens, embedding_dim)(encoder_inputs)\nencoder_conv = Conv1D(filters=128, kernel_size=3, padding='same', activation='relu')(encoder_embedding)\n\n# Attention mechanism\nattention = Dense(1, activation='tanh')(encoder_conv)\nattention = Lambda(lambda x: tf.nn.softmax(x, axis=1))(attention)\nattention = Multiply()([encoder_conv, attention])\n\n# Decoder\ndecoder_inputs = Input(shape=(None,))\ndecoder_embedding = Embedding(num_tokens, embedding_dim)(decoder_inputs)\ndecoder_conv = Conv1D(filters=128, kernel_size=3, padding='same', activation='relu')(decoder_embedding)\n\n# Combine encoder output with attention and decoder output at each time step\ncombined = Add()([attention, decoder_conv])\n\n# TimeDistributed Dense layer to predict the next token for each timestep\ndecoder_dense = TimeDistributed(Dense(num_tokens, activation='softmax'))(combined)\n\n# Seq2Seq Model\nmodel = Model([encoder_inputs, decoder_inputs], decoder_dense)\n\n# Load the weights\nmodel.load_weights('/kaggle/input/cnn-model-correction/phoneme_correction_model.h5')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-26T10:19:13.136395Z","iopub.execute_input":"2024-09-26T10:19:13.137151Z","iopub.status.idle":"2024-09-26T10:19:13.244581Z","shell.execute_reply.started":"2024-09-26T10:19:13.137115Z","shell.execute_reply":"2024-09-26T10:19:13.243589Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\n\n# Inference example\nnew_mispronounced_sequence = \"fˈɔːɹɪsʌt\"  # Replace with actual sequence\nnew_mispronounced_sequence_tokenized = tokenizer.texts_to_sequences([new_mispronounced_sequence])\nnew_mispronounced_sequence_padded = pad_sequences(new_mispronounced_sequence_tokenized, maxlen=max_sequence_length, padding='post')\n\n# Prepare the decoder input for inference\ndecoder_input = np.zeros_like(new_mispronounced_sequence_padded)\ndecoder_input[:, 1:] = new_mispronounced_sequence_padded[:, :-1]\n\n# Predict\npredicted_phonemes = model.predict([new_mispronounced_sequence_padded, decoder_input])\n\n# Get the token with the highest probability for each timestep\npredicted_token_indices = np.argmax(predicted_phonemes, axis=-1)\n\n# Create a reverse mapping from index to phoneme\nindex_to_phoneme = {index: phoneme for phoneme, index in tokenizer.word_index.items()}\nindex_to_phoneme[0] = ''  # Padding token\n\n# Decode the predicted token indices to phoneme sequences\npredicted_phoneme_sequences = []\nfor token_sequence in predicted_token_indices:\n    predicted_phoneme_sequence = ''.join([index_to_phoneme[token] for token in token_sequence])\n    predicted_phoneme_sequences.append(predicted_phoneme_sequence)\n\n# Print the decoded phoneme sequence\nfor seq in predicted_phoneme_sequences:\n    print(seq)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T10:24:34.592829Z","iopub.execute_input":"2024-08-25T10:24:34.593193Z","iopub.status.idle":"2024-08-25T10:24:37.495441Z","shell.execute_reply.started":"2024-08-25T10:24:34.593166Z","shell.execute_reply":"2024-08-25T10:24:37.494446Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\nfˈɔːɹɪst\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1724581477.480503     111 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\n# Inference example\nnew_mispronounced_sequence = \"hˈɪpzəpˌɑːɾæməs\"  # Replace with actual sequence\nnew_mispronounced_sequence_tokenized = tokenizer.texts_to_sequences([new_mispronounced_sequence])\nnew_mispronounced_sequence_padded = pad_sequences(new_mispronounced_sequence_tokenized, maxlen=max_sequence_length, padding='post')\n\n# Prepare the decoder input for inference\ndecoder_input = np.zeros_like(new_mispronounced_sequence_padded)\ndecoder_input[:, 1:] = new_mispronounced_sequence_padded[:, :-1]\n\n# Predict\npredicted_phonemes = model.predict([new_mispronounced_sequence_padded, decoder_input])\n\n# Get the token with the highest probability for each timestep\npredicted_token_indices = np.argmax(predicted_phonemes, axis=-1)\n\n# Create a reverse mapping from index to phoneme\nindex_to_phoneme = {index: phoneme for phoneme, index in tokenizer.word_index.items()}\nindex_to_phoneme[0] = ''  # Padding token\n\n# Decode the predicted token indices to phoneme sequences\npredicted_phoneme_sequences = []\nfor token_sequence in predicted_token_indices:\n    predicted_phoneme_sequence = ''.join([index_to_phoneme[token] for token in token_sequence])\n    predicted_phoneme_sequences.append(predicted_phoneme_sequence)\n\n# Print the decoded phoneme sequence\nfor seq in predicted_phoneme_sequences:\n    print(seq)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T10:26:56.640032Z","iopub.execute_input":"2024-08-25T10:26:56.640747Z","iopub.status.idle":"2024-08-25T10:26:56.713445Z","shell.execute_reply.started":"2024-08-25T10:26:56.640713Z","shell.execute_reply":"2024-08-25T10:26:56.712445Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\nhˈɪpəppˌɑːɾmməs\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\n# Inference example\nnew_mispronounced_sequence = \"ɹˈɪvɪtɛ\"  # Replace with actual sequence\nnew_mispronounced_sequence_tokenized = tokenizer.texts_to_sequences([new_mispronounced_sequence])\nnew_mispronounced_sequence_padded = pad_sequences(new_mispronounced_sequence_tokenized, maxlen=max_sequence_length, padding='post')\n\n# Prepare the decoder input for inference\ndecoder_input = np.zeros_like(new_mispronounced_sequence_padded)\ndecoder_input[:, 1:] = new_mispronounced_sequence_padded[:, :-1]\n\n# Predict\npredicted_phonemes = model.predict([new_mispronounced_sequence_padded, decoder_input])\n\n# Get the token with the highest probability for each timestep\npredicted_token_indices = np.argmax(predicted_phonemes, axis=-1)\n\n# Create a reverse mapping from index to phoneme\nindex_to_phoneme = {index: phoneme for phoneme, index in tokenizer.word_index.items()}\nindex_to_phoneme[0] = ''  # Padding token\n\n# Decode the predicted token indices to phoneme sequences\npredicted_phoneme_sequences = []\nfor token_sequence in predicted_token_indices:\n    predicted_phoneme_sequence = ''.join([index_to_phoneme[token] for token in token_sequence])\n    predicted_phoneme_sequences.append(predicted_phoneme_sequence)\n\n# Print the decoded phoneme sequence\nfor seq in predicted_phoneme_sequences:\n    print(seq)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-26T11:13:13.820696Z","iopub.execute_input":"2024-09-26T11:13:13.821384Z","iopub.status.idle":"2024-09-26T11:13:13.894476Z","shell.execute_reply.started":"2024-09-26T11:13:13.821355Z","shell.execute_reply":"2024-09-26T11:13:13.893653Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\nɹˈɪvɪt\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\n# Inference example\nnew_mispronounced_sequence = \"ˈæpθt\"  # Replace with actual sequence\nnew_mispronounced_sequence_tokenized = tokenizer.texts_to_sequences([new_mispronounced_sequence])\nnew_mispronounced_sequence_padded = pad_sequences(new_mispronounced_sequence_tokenized, maxlen=max_sequence_length, padding='post')\n\n# Prepare the decoder input for inference\ndecoder_input = np.zeros_like(new_mispronounced_sequence_padded)\ndecoder_input[:, 1:] = new_mispronounced_sequence_padded[:, :-1]\n\n# Predict\npredicted_phonemes = model.predict([new_mispronounced_sequence_padded, decoder_input])\n\n# Get the token with the highest probability for each timestep\npredicted_token_indices = np.argmax(predicted_phonemes, axis=-1)\n\n# Create a reverse mapping from index to phoneme\nindex_to_phoneme = {index: phoneme for phoneme, index in tokenizer.word_index.items()}\nindex_to_phoneme[0] = ''  # Padding token\n\n# Decode the predicted token indices to phoneme sequences\npredicted_phoneme_sequences = []\nfor token_sequence in predicted_token_indices:\n    predicted_phoneme_sequence = ''.join([index_to_phoneme[token] for token in token_sequence])\n    predicted_phoneme_sequences.append(predicted_phoneme_sequence)\n\n# Print the decoded phoneme sequence\nfor seq in predicted_phoneme_sequences:\n    print(seq)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T10:36:28.188135Z","iopub.execute_input":"2024-08-25T10:36:28.188544Z","iopub.status.idle":"2024-08-25T10:36:28.262450Z","shell.execute_reply.started":"2024-08-25T10:36:28.188512Z","shell.execute_reply":"2024-08-25T10:36:28.261552Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\nˈæpt\n","output_type":"stream"}]}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9515895,"sourceType":"datasetVersion","datasetId":5793124}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.layers import Embedding, GRU, Dense, Input, Bidirectional\nfrom tensorflow.keras.models import Model\nimport tensorflow as tf\n\n# Load the dataset\ndf = pd.read_csv('/kaggle/input/gru-dataset-text/capstone_dataset_hugging_face.csv')\n\n# Prepare the data\nX = pd.concat([df['ipa_phoneme'], df['incorrect_ipa_phoneme']], axis=0)\ny = pd.concat([pd.Series([0] * len(df)), pd.Series([1] * len(df))], axis=0)\n\n# Tokenize the phoneme sequences\ntokenizer = Tokenizer(char_level=True)  # Character-level tokenization\ntokenizer.fit_on_texts(X)\nX_tokenized = tokenizer.texts_to_sequences(X)\nX_padded = pad_sequences(X_tokenized, padding='post', maxlen=128)  # Padding the sequences\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=42)\n\n# Define the model parameters\nvocab_size = len(tokenizer.word_index) + 1  # Vocabulary size based on tokenized phonemes\nembedding_dim = 64  # Dimension of the embedding layer\ngru_units = 64  # Number of GRU units\nsequence_length = X_padded.shape[1]  # Length of input sequences\n\n# Build the GRU-based model\ninputs = Input(shape=(sequence_length,))\nembedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=sequence_length)(inputs)\ngru = Bidirectional(GRU(gru_units, return_sequences=False))(embedding)  # Bidirectional GRU\ndense = Dense(64, activation='relu')(gru)  # Dense layer\noutput = Dense(1, activation='sigmoid')(dense)  # Output layer for binary classification\n\n# Define the model\nmodel = Model(inputs=inputs, outputs=output)\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Model summary\nmodel.summary()\n\n# Train the model\nhistory = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n\n# Evaluate the model\nloss, accuracy = model.evaluate(X_test, y_test)\nprint(f'Test Accuracy: {accuracy}')\n\n# Save the model\nmodel.save('/kaggle/working/gru_phoneme_classification_model.h5')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T11:50:25.464990Z","iopub.execute_input":"2024-09-30T11:50:25.465619Z","iopub.status.idle":"2024-09-30T12:25:38.663275Z","shell.execute_reply.started":"2024-09-30T11:50:25.465579Z","shell.execute_reply":"2024-09-30T12:25:38.662338Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m3,328\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m49,920\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,328</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,920</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m61,569\u001b[0m (240.50 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">61,569</span> (240.50 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m61,569\u001b[0m (240.50 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">61,569</span> (240.50 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/10\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 15ms/step - accuracy: 0.7475 - loss: 0.4819 - val_accuracy: 0.8659 - val_loss: 0.3205\nEpoch 2/10\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 15ms/step - accuracy: 0.8714 - loss: 0.3085 - val_accuracy: 0.8809 - val_loss: 0.2912\nEpoch 3/10\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 15ms/step - accuracy: 0.8830 - loss: 0.2864 - val_accuracy: 0.8850 - val_loss: 0.2826\nEpoch 4/10\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 15ms/step - accuracy: 0.8892 - loss: 0.2742 - val_accuracy: 0.8883 - val_loss: 0.2760\nEpoch 5/10\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 15ms/step - accuracy: 0.8928 - loss: 0.2668 - val_accuracy: 0.8934 - val_loss: 0.2677\nEpoch 6/10\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 15ms/step - accuracy: 0.8942 - loss: 0.2619 - val_accuracy: 0.8916 - val_loss: 0.2695\nEpoch 7/10\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 15ms/step - accuracy: 0.8973 - loss: 0.2577 - val_accuracy: 0.8922 - val_loss: 0.2699\nEpoch 8/10\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 15ms/step - accuracy: 0.8989 - loss: 0.2544 - val_accuracy: 0.8947 - val_loss: 0.2644\nEpoch 9/10\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 15ms/step - accuracy: 0.8995 - loss: 0.2524 - val_accuracy: 0.8951 - val_loss: 0.2648\nEpoch 10/10\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 15ms/step - accuracy: 0.9004 - loss: 0.2512 - val_accuracy: 0.8958 - val_loss: 0.2634\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.8953 - loss: 0.2635\nTest Accuracy: 0.8957725167274475\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.preprocessing.text import Tokenizer\n\n# Load the saved model\nmodel = load_model('/kaggle/working/gru_phoneme_classification_model.h5')\n\n# Load the same tokenizer used during training\n# Assuming the tokenizer is saved or can be recreated using the training data\n# You may need to fit the tokenizer on the same vocabulary as the training data\ntokenizer = Tokenizer(char_level=True)  # Character-level tokenization as before\nX = pd.concat([df['ipa_phoneme'], df['incorrect_ipa_phoneme']], axis=0)  # Use the dataset's phonemes\ntokenizer.fit_on_texts(X)  # Fit on the training data\n\n# Define a function to predict if a list of phonemes is correct or mispronounced\ndef predict_phoneme_sequence(phoneme_list):\n    # Tokenize and pad the input phoneme list\n    phoneme_tokenized = tokenizer.texts_to_sequences(phoneme_list)\n    phoneme_padded = pad_sequences(phoneme_tokenized, padding='post', maxlen=128)\n    \n    # Predict using the loaded model\n    predictions = model.predict(phoneme_padded)\n    \n    # Interpret the predictions: if prediction >= 0.5, it's considered mispronounced\n    results = ['Correct' if pred < 0.5 else 'Mispronounced' for pred in predictions]\n    \n    return results\n\n# Example usage with a list of phoneme sequences (in IPA format)\nphoneme_list = ['fˈɔːɹɪsʌt', 'fˈɔːɹɪst', 'kˈælkjʊlˌeɪɾɚ','dʒɛnər','sˈæŋkːtjuːˌɛɹi','ɛkˈsprɛsoʊ','ɛk ˈsɛtərə','mɛˈænɪkwˌɪn','kˈæʃ','bʊˈkɛt']  # Example phoneme sequences\nresults = predict_phoneme_sequence(phoneme_list)\n\n# Print the results\nfor i, phoneme in enumerate(phoneme_list):\n    print(f'Phoneme sequence: {phoneme} - Prediction: {results[i]}')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T13:46:58.531526Z","iopub.execute_input":"2024-09-30T13:46:58.531918Z","iopub.status.idle":"2024-09-30T13:47:02.650479Z","shell.execute_reply.started":"2024-09-30T13:46:58.531881Z","shell.execute_reply":"2024-09-30T13:47:02.649451Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\nPhoneme sequence: fˈɔːɹɪsʌt - Prediction: Mispronounced\nPhoneme sequence: fˈɔːɹɪst - Prediction: Correct\nPhoneme sequence: kˈælkjʊlˌeɪɾɚ - Prediction: Correct\nPhoneme sequence: dʒɛnər - Prediction: Mispronounced\nPhoneme sequence: sˈæŋkːtjuːˌɛɹi - Prediction: Mispronounced\nPhoneme sequence: ɛkˈsprɛsoʊ - Prediction: Mispronounced\nPhoneme sequence: ɛk ˈsɛtərə - Prediction: Mispronounced\nPhoneme sequence: mɛˈænɪkwˌɪn - Prediction: Mispronounced\nPhoneme sequence: kˈæʃ - Prediction: Correct\nPhoneme sequence: bʊˈkɛt - Prediction: Mispronounced\n","output_type":"stream"}]}]}
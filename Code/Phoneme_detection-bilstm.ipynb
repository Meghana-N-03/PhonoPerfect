{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8950849,"sourceType":"datasetVersion","datasetId":5386602},{"sourceId":8951178,"sourceType":"datasetVersion","datasetId":5386844},{"sourceId":8955881,"sourceType":"datasetVersion","datasetId":5389868},{"sourceId":8957969,"sourceType":"datasetVersion","datasetId":5391426}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-13T06:39:14.320571Z","iopub.execute_input":"2024-08-13T06:39:14.321012Z","iopub.status.idle":"2024-08-13T06:39:14.806815Z","shell.execute_reply.started":"2024-08-13T06:39:14.320978Z","shell.execute_reply":"2024-08-13T06:39:14.805545Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/input/modified-hrmodel/modified_model.h5\n/kaggle/input/calssification-phoneme-model/phoneme_classification_model.h5\n/kaggle/input/a-z-combineddataset/a_z_combibed.csv\n/kaggle/input/huggingface-captone/capstone_dataset_hugging_face.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"**accuracy : 83%***   using lstm","metadata":{}},{"cell_type":"code","source":"# accuracy : 90%  bilstm","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","metadata":{"execution":{"iopub.status.busy":"2024-09-26T02:58:56.999363Z","iopub.execute_input":"2024-09-26T02:58:57.000356Z","iopub.status.idle":"2024-09-26T02:59:09.856233Z","shell.execute_reply.started":"2024-09-26T02:58:57.000318Z","shell.execute_reply":"2024-09-26T02:59:09.855190Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2024-09-26 02:58:59.806307: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-09-26 02:58:59.806426: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-09-26 02:58:59.939902: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Load the dataset\ndf = pd.read_csv('/kaggle/input/huggingface-captone/capstone_dataset_hugging_face.csv')\n# Create labels and concatenate phoneme sequences\nX = pd.concat([df['ipa_phoneme'], df['incorrect_ipa_phoneme']], axis=0)\ny = pd.concat([pd.Series([0] * len(df)), pd.Series([1] * len(df))], axis=0)\n\n# Tokenize the phonemes\ntokenizer = Tokenizer(char_level=True)  # character-level tokenization\ntokenizer.fit_on_texts(X)\nX_tokenized = tokenizer.texts_to_sequences(X)\nX_padded = pad_sequences(X_tokenized, padding='post')","metadata":{"execution":{"iopub.status.busy":"2024-09-26T02:59:12.461287Z","iopub.execute_input":"2024-09-26T02:59:12.461947Z","iopub.status.idle":"2024-09-26T02:59:21.012309Z","shell.execute_reply.started":"2024-09-26T02:59:12.461913Z","shell.execute_reply":"2024-09-26T02:59:21.011385Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=42)\n\n# Build the model\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.build(input_shape=(None, X_padded.shape[1]))  # Ensure the model is built with the correct input shape\nmodel.summary()\n\n# Train the model\nhistory = model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))\n\n# Evaluate the model\nloss, accuracy = model.evaluate(X_test, y_test)\nprint(f'Test Accuracy: {accuracy}')\n\n# Save the model\n# model.save('phoneme_classification_model.h5')\nmodel.save_weights('/kaggle/working/save/weights')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:46:47.716385Z","iopub.execute_input":"2024-07-15T10:46:47.717309Z","iopub.status.idle":"2024-07-15T12:14:17.322006Z","shell.execute_reply.started":"2024-07-15T10:46:47.717254Z","shell.execute_reply":"2024-07-15T12:14:17.320333Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m3,328\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m66,048\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,328</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m77,697\u001b[0m (303.50 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">77,697</span> (303.50 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m77,697\u001b[0m (303.50 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">77,697</span> (303.50 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 7ms/step - accuracy: 0.7440 - loss: 0.4878 - val_accuracy: 0.8626 - val_loss: 0.3238\nEpoch 2/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 7ms/step - accuracy: 0.8686 - loss: 0.3124 - val_accuracy: 0.8788 - val_loss: 0.2925\nEpoch 3/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 7ms/step - accuracy: 0.8829 - loss: 0.2863 - val_accuracy: 0.8860 - val_loss: 0.2804\nEpoch 4/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 7ms/step - accuracy: 0.8899 - loss: 0.2724 - val_accuracy: 0.8912 - val_loss: 0.2725\nEpoch 5/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 7ms/step - accuracy: 0.8944 - loss: 0.2632 - val_accuracy: 0.8931 - val_loss: 0.2683\nEpoch 6/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 7ms/step - accuracy: 0.8977 - loss: 0.2556 - val_accuracy: 0.8957 - val_loss: 0.2628\nEpoch 7/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 7ms/step - accuracy: 0.9016 - loss: 0.2485 - val_accuracy: 0.8961 - val_loss: 0.2606\nEpoch 8/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 7ms/step - accuracy: 0.9028 - loss: 0.2466 - val_accuracy: 0.8986 - val_loss: 0.2597\nEpoch 9/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 8ms/step - accuracy: 0.9052 - loss: 0.2410 - val_accuracy: 0.8992 - val_loss: 0.2582\nEpoch 10/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 7ms/step - accuracy: 0.9066 - loss: 0.2383 - val_accuracy: 0.8967 - val_loss: 0.2603\nEpoch 11/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 7ms/step - accuracy: 0.9068 - loss: 0.2370 - val_accuracy: 0.8981 - val_loss: 0.2570\nEpoch 12/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 7ms/step - accuracy: 0.9085 - loss: 0.2329 - val_accuracy: 0.8994 - val_loss: 0.2578\nEpoch 13/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 7ms/step - accuracy: 0.9099 - loss: 0.2313 - val_accuracy: 0.9005 - val_loss: 0.2568\nEpoch 14/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 7ms/step - accuracy: 0.9113 - loss: 0.2287 - val_accuracy: 0.9002 - val_loss: 0.2577\nEpoch 15/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 7ms/step - accuracy: 0.9114 - loss: 0.2275 - val_accuracy: 0.9011 - val_loss: 0.2556\nEpoch 16/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 7ms/step - accuracy: 0.9120 - loss: 0.2266 - val_accuracy: 0.8995 - val_loss: 0.2587\nEpoch 17/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 8ms/step - accuracy: 0.9127 - loss: 0.2251 - val_accuracy: 0.9001 - val_loss: 0.2579\nEpoch 18/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 8ms/step - accuracy: 0.9133 - loss: 0.2234 - val_accuracy: 0.9020 - val_loss: 0.2558\nEpoch 19/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 7ms/step - accuracy: 0.9140 - loss: 0.2225 - val_accuracy: 0.9017 - val_loss: 0.2550\nEpoch 20/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 7ms/step - accuracy: 0.9149 - loss: 0.2200 - val_accuracy: 0.9017 - val_loss: 0.2558\nEpoch 21/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 7ms/step - accuracy: 0.9152 - loss: 0.2189 - val_accuracy: 0.9017 - val_loss: 0.2550\nEpoch 22/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 7ms/step - accuracy: 0.9157 - loss: 0.2177 - val_accuracy: 0.9019 - val_loss: 0.2551\nEpoch 23/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 7ms/step - accuracy: 0.9157 - loss: 0.2182 - val_accuracy: 0.9012 - val_loss: 0.2577\nEpoch 24/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 7ms/step - accuracy: 0.9163 - loss: 0.2163 - val_accuracy: 0.9011 - val_loss: 0.2570\nEpoch 25/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 7ms/step - accuracy: 0.9176 - loss: 0.2147 - val_accuracy: 0.9010 - val_loss: 0.2575\nEpoch 26/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 8ms/step - accuracy: 0.9166 - loss: 0.2162 - val_accuracy: 0.9020 - val_loss: 0.2575\nEpoch 27/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 8ms/step - accuracy: 0.9167 - loss: 0.2163 - val_accuracy: 0.9017 - val_loss: 0.2569\nEpoch 28/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 8ms/step - accuracy: 0.9174 - loss: 0.2143 - val_accuracy: 0.9025 - val_loss: 0.2572\nEpoch 29/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 8ms/step - accuracy: 0.9178 - loss: 0.2147 - val_accuracy: 0.9015 - val_loss: 0.2596\nEpoch 30/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 8ms/step - accuracy: 0.9180 - loss: 0.2132 - val_accuracy: 0.9013 - val_loss: 0.2579\nEpoch 31/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 7ms/step - accuracy: 0.9175 - loss: 0.2140 - val_accuracy: 0.9019 - val_loss: 0.2589\nEpoch 32/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 8ms/step - accuracy: 0.9187 - loss: 0.2119 - val_accuracy: 0.9013 - val_loss: 0.2600\nEpoch 33/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 7ms/step - accuracy: 0.9192 - loss: 0.2112 - val_accuracy: 0.9009 - val_loss: 0.2593\nEpoch 34/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 7ms/step - accuracy: 0.9197 - loss: 0.2101 - val_accuracy: 0.8983 - val_loss: 0.2658\nEpoch 35/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 7ms/step - accuracy: 0.9204 - loss: 0.2084 - val_accuracy: 0.9003 - val_loss: 0.2600\nEpoch 36/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 7ms/step - accuracy: 0.9188 - loss: 0.2114 - val_accuracy: 0.9005 - val_loss: 0.2624\nEpoch 37/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 7ms/step - accuracy: 0.9193 - loss: 0.2105 - val_accuracy: 0.9014 - val_loss: 0.2571\nEpoch 38/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 8ms/step - accuracy: 0.9194 - loss: 0.2095 - val_accuracy: 0.9011 - val_loss: 0.2612\nEpoch 39/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 7ms/step - accuracy: 0.9194 - loss: 0.2097 - val_accuracy: 0.9012 - val_loss: 0.2609\nEpoch 40/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 7ms/step - accuracy: 0.9201 - loss: 0.2095 - val_accuracy: 0.9002 - val_loss: 0.2621\nEpoch 41/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 7ms/step - accuracy: 0.9195 - loss: 0.2095 - val_accuracy: 0.9013 - val_loss: 0.2589\nEpoch 42/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 7ms/step - accuracy: 0.9208 - loss: 0.2077 - val_accuracy: 0.9008 - val_loss: 0.2594\nEpoch 43/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 7ms/step - accuracy: 0.9200 - loss: 0.2084 - val_accuracy: 0.9009 - val_loss: 0.2609\nEpoch 44/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 7ms/step - accuracy: 0.9207 - loss: 0.2069 - val_accuracy: 0.9016 - val_loss: 0.2604\nEpoch 45/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 7ms/step - accuracy: 0.9201 - loss: 0.2078 - val_accuracy: 0.9012 - val_loss: 0.2612\nEpoch 46/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 7ms/step - accuracy: 0.9208 - loss: 0.2063 - val_accuracy: 0.9008 - val_loss: 0.2614\nEpoch 47/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 7ms/step - accuracy: 0.9212 - loss: 0.2064 - val_accuracy: 0.8994 - val_loss: 0.2645\nEpoch 48/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 8ms/step - accuracy: 0.9206 - loss: 0.2064 - val_accuracy: 0.9016 - val_loss: 0.2592\nEpoch 49/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 7ms/step - accuracy: 0.9212 - loss: 0.2055 - val_accuracy: 0.9023 - val_loss: 0.2581\nEpoch 50/50\n\u001b[1m13747/13747\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 8ms/step - accuracy: 0.9204 - loss: 0.2072 - val_accuracy: 0.9002 - val_loss: 0.2634\n\u001b[1m3437/3437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8998 - loss: 0.2632\nTest Accuracy: 0.9002282619476318\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[24], line 45\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# model.save('phoneme_classification_model.h5')\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/working/save/weights\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/saving/saving_api.py:217\u001b[0m, in \u001b[0;36msave_weights\u001b[0;34m(model, filepath, overwrite, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.saving.save_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_weights\u001b[39m(model, filepath, overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    218\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe filename must end in `.weights.h5`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    220\u001b[0m         )\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m         exists \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(filepath)\n","\u001b[0;31mValueError\u001b[0m: The filename must end in `.weights.h5`. Received: filepath=/kaggle/working/save/weights"],"ename":"ValueError","evalue":"The filename must end in `.weights.h5`. Received: filepath=/kaggle/working/save/weights","output_type":"error"}],"execution_count":24},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2024-09-11T14:42:55.536233Z","iopub.execute_input":"2024-09-11T14:42:55.536750Z","iopub.status.idle":"2024-09-11T14:42:55.543007Z","shell.execute_reply.started":"2024-09-11T14:42:55.536717Z","shell.execute_reply":"2024-09-11T14:42:55.541679Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"model.save('phoneme_classification_model.h5')","metadata":{"execution":{"iopub.status.busy":"2024-09-11T14:44:16.451211Z","iopub.execute_input":"2024-09-11T14:44:16.451669Z","iopub.status.idle":"2024-09-11T14:44:16.506601Z","shell.execute_reply.started":"2024-09-11T14:44:16.451632Z","shell.execute_reply":"2024-09-11T14:44:16.505364Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Save the model\n\nloaded_model= tf.keras.models.load_model('/kaggle/input/calssification-phoneme-model/phoneme_classification_model.h5')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-26T02:59:44.551563Z","iopub.execute_input":"2024-09-26T02:59:44.552223Z","iopub.status.idle":"2024-09-26T02:59:44.755432Z","shell.execute_reply.started":"2024-09-26T02:59:44.552190Z","shell.execute_reply":"2024-09-26T02:59:44.754571Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\n\n# Assuming you have the original dataset loaded as df\nX = pd.concat([df['ipa_phoneme'], df['incorrect_ipa_phoneme']], axis=0)\n\n# Recreate the tokenizer\ntokenizer = Tokenizer(char_level=True)  # character-level tokenization\ntokenizer.fit_on_texts(X)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-26T02:59:48.393751Z","iopub.execute_input":"2024-09-26T02:59:48.394706Z","iopub.status.idle":"2024-09-26T02:59:51.892317Z","shell.execute_reply.started":"2024-09-26T02:59:48.394672Z","shell.execute_reply":"2024-09-26T02:59:51.891068Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Define a function to preprocess and predict for each phoneme\ndef predict_each_phoneme(loaded_model, tokenizer, phonemes):\n    predictions = []\n    for phoneme in phonemes:\n        # Tokenize the phoneme\n        phoneme_tokenized = tokenizer.texts_to_sequences([phoneme])\n        phoneme_padded = pad_sequences(phoneme_tokenized, padding='post', maxlen=X_padded.shape[1])\n\n        # Predict using the model\n        prediction = loaded_model.predict(phoneme_padded)\n\n        # Interpret the prediction\n        if prediction[0] > 0.5:\n            predictions.append((phoneme, \"Mispronounced\"))\n        else:\n            predictions.append((phoneme, \"Correctly pronounced\"))\n    \n    return predictions\n\n# Recreate the tokenizer using the original dataset\nX = pd.concat([df['ipa_phoneme'], df['incorrect_ipa_phoneme']], axis=0)\ntokenizer = Tokenizer(char_level=True)\ntokenizer.fit_on_texts(X)\n\n# Load the trained model\n# loaded_model = tf.keras.models.load_model('/path/to/saved/model')\n\n# Example phonemes list (assuming input as a list of phonemes)\n# phonemes_list =['ɐ pˈɔːkɐlˌɒpsiː','ɪz','kˈʌmɪŋ','ˈɔːlweɪz','juː','wˈɒnt','tuː',' sˈiː','aɪtˈiː','ɪnðə','suːpˈɜːlətˌɪv','dɪɡɹˈiː']  # Replace with actual phoneme sequence\nphonemes_list =[\"kˈælkjʊlˌeɪɾɚ\"] \n# Predict for each phoneme\nresults = predict_each_phoneme(loaded_model, tokenizer, phonemes_list)\n\n# Print the results\nfor phoneme, result in results:\n    print(f'Phoneme: {phoneme}, Result: {result}')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-26T03:51:57.428898Z","iopub.execute_input":"2024-09-26T03:51:57.429643Z","iopub.status.idle":"2024-09-26T03:52:00.944060Z","shell.execute_reply.started":"2024-09-26T03:51:57.429608Z","shell.execute_reply":"2024-09-26T03:52:00.943017Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\nPhoneme: kˈælkjʊlˌeɪɾɚ, Result: Correctly pronounced\n","output_type":"stream"}],"execution_count":20}]}